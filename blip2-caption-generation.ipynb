{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":45917,"databundleVersionId":5024308,"sourceType":"competition"},{"sourceId":4988409,"sourceType":"datasetVersion","datasetId":2893282},{"sourceId":5053447,"sourceType":"datasetVersion","datasetId":2934068},{"sourceId":5055324,"sourceType":"datasetVersion","datasetId":2935195},{"sourceId":5055327,"sourceType":"datasetVersion","datasetId":2935198},{"sourceId":5055426,"sourceType":"datasetVersion","datasetId":2935266},{"sourceId":5057410,"sourceType":"datasetVersion","datasetId":2936493},{"sourceId":7107722,"sourceType":"datasetVersion","datasetId":4097887},{"sourceId":7117666,"sourceType":"datasetVersion","datasetId":4101452},{"sourceId":120141306,"sourceType":"kernelVersion"},{"sourceId":120200988,"sourceType":"kernelVersion"}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install salesforce-lavis --no-index --find-links=file:///kaggle/input/lavis-pip/","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip uninstall -y salesforce-lavis","metadata":{"execution":{"iopub.status.busy":"2023-12-13T16:15:25.438824Z","iopub.execute_input":"2023-12-13T16:15:25.439729Z","iopub.status.idle":"2023-12-13T16:15:27.431909Z","shell.execute_reply.started":"2023-12-13T16:15:25.439675Z","shell.execute_reply":"2023-12-13T16:15:27.430719Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nFound existing installation: salesforce-lavis 1.0.0\nUninstalling salesforce-lavis-1.0.0:\n  Successfully uninstalled salesforce-lavis-1.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install salesforce-lavis --no-index --find-links=file:///kaggle/input/lavis-mod-wheel/salesforce_lavis-1.0.0.dev1-py3-none-any.whl","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport sys\nimport torch\n\nimport numpy as np\nimport torch.nn as nn\nimport pandas as pd\nimport polars as pl\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom lavis.models import load_model, load_preprocess, load_model_and_preprocess\nfrom lavis.processors import load_processor\nfrom lavis.models.blip2_models.blip2_opt import Blip2OPT\nfrom typing import Dict\nfrom sklearn.metrics.pairwise import cosine_similarity \nfrom pathlib import Path\nfrom accelerate import init_empty_weights\n\nsys.path.append('/kaggle/input/sentence-transformers-222/sentence-transformers')\nfrom sentence_transformers import SentenceTransformer, models","metadata":{"execution":{"iopub.status.busy":"2023-12-13T16:15:40.832932Z","iopub.execute_input":"2023-12-13T16:15:40.833282Z","iopub.status.idle":"2023-12-13T16:15:56.851707Z","shell.execute_reply.started":"2023-12-13T16:15:40.833251Z","shell.execute_reply":"2023-12-13T16:15:56.850541Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# these helper functions are based on the following repository. \n# https://github.com/FrancescoSaverioZuppichini/Loading-huge-PyTorch-models-with-linear-memory-consumption/blob/main/README.md\ndef get_keys_to_submodule(model: nn.Module) -> Dict[str, nn.Module]:\n    keys_to_submodule = {}\n    for submodule_name, submodule in model.named_modules():\n        for param_name, param in submodule.named_parameters():\n            splitted_param_name = param_name.split('.')\n            is_leaf_param = len(splitted_param_name) == 1\n            if is_leaf_param:\n                if submodule_name != '':\n                    key = f\"{submodule_name}.{param_name}\"\n                else:\n                    key = param_name\n                keys_to_submodule[key] = submodule                \n    return keys_to_submodule\n\n\ndef load_state_dict_with_low_memory(model: nn.Module, state_dict: Dict[str, torch.Tensor]):\n    model.to(torch.device(\"meta\"))\n    keys_to_submodule = get_keys_to_submodule(model)\n    for key, submodule in keys_to_submodule.items():\n        val = state_dict.get(key)\n        \n        if val is not None:\n            param_name = key.split('.')[-1]\n            param_dtype = getattr(submodule, param_name).dtype\n            val = val.to(param_dtype)\n            new_val = torch.nn.Parameter(val, requires_grad=False)\n            setattr(submodule, param_name, new_val)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T16:15:56.853270Z","iopub.execute_input":"2023-12-13T16:15:56.854601Z","iopub.status.idle":"2023-12-13T16:15:56.865521Z","shell.execute_reply.started":"2023-12-13T16:15:56.854558Z","shell.execute_reply":"2023-12-13T16:15:56.864375Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"comp_path = Path('/kaggle/input/stable-diffusion-image-to-prompts/')\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-12-13T16:15:56.867077Z","iopub.execute_input":"2023-12-13T16:15:56.867940Z","iopub.status.idle":"2023-12-13T16:15:57.027717Z","shell.execute_reply.started":"2023-12-13T16:15:56.867884Z","shell.execute_reply":"2023-12-13T16:15:57.026513Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"with init_empty_weights():\n    my_model = Blip2OPT(opt_model=\"facebook/opt-2.7b\")","metadata":{"execution":{"iopub.status.busy":"2023-12-13T16:15:57.029014Z","iopub.execute_input":"2023-12-13T16:15:57.029335Z","iopub.status.idle":"2023-12-13T16:17:08.633542Z","shell.execute_reply.started":"2023-12-13T16:15:57.029307Z","shell.execute_reply":"2023-12-13T16:17:08.632413Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class DictWrapper:\n    def __init__(self, d):\n        self.dict = d\n    \n    def __getattr__(self, name):\n        return self.dict[name]\n\n    def get(self, name, default_val=None):\n        return self.dict.get(name, default_val)\n\ndict_tr = {\n    \"name\": \"blip_image_train\",\n    \"image_size\": 224\n}\ndict_ev = {\n    \"name\": \"blip_image_eval\",\n    \"image_size\": 224\n}\ndict_t = {\n    \"name\": \"blip_caption\"\n}\nconfig = {\n    \"vis_processor\":{\n        \"train\":DictWrapper(dict_tr),\n        \"eval\":DictWrapper(dict_ev),\n    },\n    \"text_processor\":{\n        \"train\":DictWrapper(dict_t),\n        \"eval\":DictWrapper(dict_t)\n    }\n}\nvis_processors = load_preprocess(config)[0]","metadata":{"execution":{"iopub.status.busy":"2023-12-13T16:17:08.634839Z","iopub.execute_input":"2023-12-13T16:17:08.635162Z","iopub.status.idle":"2023-12-13T16:17:08.644336Z","shell.execute_reply.started":"2023-12-13T16:17:08.635133Z","shell.execute_reply":"2023-12-13T16:17:08.643331Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"load_state_dict_with_low_memory(my_model, torch.load(\"/kaggle/input/blip2-pretrained-opt27b-sdpth/blip2_pretrained_opt2.7b_sd.pth\"))\nmy_model.eval()\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os\n\ndata_path = '/kaggle/input/sample-data/sample.csv'\ndata_df = pd.read_excel(data_path)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T16:18:23.139814Z","iopub.execute_input":"2023-12-13T16:18:23.140130Z","iopub.status.idle":"2023-12-13T16:18:42.144169Z","shell.execute_reply.started":"2023-12-13T16:18:23.140102Z","shell.execute_reply":"2023-12-13T16:18:42.143273Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"folder_path = '/kaggle/input/sample-data/media'","metadata":{"execution":{"iopub.status.busy":"2023-12-13T16:24:13.094655Z","iopub.execute_input":"2023-12-13T16:24:13.095098Z","iopub.status.idle":"2023-12-13T16:24:13.651326Z","shell.execute_reply.started":"2023-12-13T16:24:13.095061Z","shell.execute_reply":"2023-12-13T16:24:13.650170Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"pred_prompt_list = []\ni=0\nfor ids in data_df['id']:\n    if i%100==0:\n        print(f\"processed {i}th example\")\n    image_num = str(ids-1)+'.jpg'\n    image_path = os.path.join(folder_path, image_num)\n    image = Image.open(image_path).convert('RGB')\n    image = vis_processors[\"eval\"](image).unsqueeze(0).to(device)\n    pred_prompt = my_model.generate({\"image\": image}, num_beams=3)\n    pred_prompt_list.append(pred_prompt[0])\n    i+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame()\ndata['caption'] = pred_prompt_list\ndata['id'] = data_df['id']\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-13T18:06:42.958022Z","iopub.execute_input":"2023-12-13T18:06:42.958408Z","iopub.status.idle":"2023-12-13T18:06:42.975804Z","shell.execute_reply.started":"2023-12-13T18:06:42.958376Z","shell.execute_reply":"2023-12-13T18:06:42.974562Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                             caption  id\n0     a large concrete tower in the middle of a city   6\n1             a woman sitting at a desk in an office   8\n2  a man in a suit and tie sits in front of a tel...  13\n3          two people riding bicycles on a dirt road  14\n4  a firefighter is walking on the runway at an a...  17","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a large concrete tower in the middle of a city</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a woman sitting at a desk in an office</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a man in a suit and tie sits in front of a tel...</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>two people riding bicycles on a dirt road</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a firefighter is walking on the runway at an a...</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.to_csv(\"/kaggle/working/data.csv\",index = False)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T18:07:10.513447Z","iopub.execute_input":"2023-12-13T18:07:10.514365Z","iopub.status.idle":"2023-12-13T18:07:10.532722Z","shell.execute_reply.started":"2023-12-13T18:07:10.514325Z","shell.execute_reply":"2023-12-13T18:07:10.531673Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}